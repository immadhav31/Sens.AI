{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Main Problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gowri\\AppData\\Local\\Temp\\ipykernel_33616\\3302940520.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pod_data.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pod_multigpu = pd.read_csv('openb_pod_list_multigpu50.csv')\n",
    "pod_gpushare = pd.read_csv('openb_pod_list_gpushare100.csv')\n",
    "pod_cpu = pd.read_csv('openb_pod_list_cpu300.csv')\n",
    "node_data = pd.read_csv('openb_node_list_all_node.csv')\n",
    "\n",
    "pod_data = pd.concat([pod_multigpu, pod_gpushare, pod_cpu], ignore_index=True)\n",
    "\n",
    "time_columns = ['creation_time', 'deletion_time', 'scheduled_time']\n",
    "for col in time_columns:\n",
    "    if col in pod_data.columns:\n",
    "        pod_data[col] = pd.to_numeric(pod_data[col], errors='coerce')\n",
    "\n",
    "pod_data = pd.merge(pod_data, node_data, left_on='name', right_on='sn', how='left')\n",
    "\n",
    "pod_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'cpu_milli_x', 'memory_mib_x', 'num_gpu', 'gpu_milli',\n",
      "       'gpu_spec', 'qos', 'pod_phase', 'creation_time', 'deletion_time',\n",
      "       'scheduled_time', 'sn', 'cpu_milli_y', 'memory_mib_y', 'gpu', 'model'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pod_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Columns: Index(['name', 'cpu_milli', 'memory_mib', 'num_gpu', 'gpu_milli', 'gpu_spec',\n",
      "       'qos', 'pod_phase', 'creation_time', 'deletion_time', 'scheduled_time',\n",
      "       'sn', 'gpu', 'model'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pod_data.rename(columns={'cpu_milli_x': 'cpu_milli', 'memory_mib_x': 'memory_mib'}, inplace=True)\n",
    "\n",
    "pod_data.drop(columns=['cpu_milli_y', 'memory_mib_y'], inplace=True, errors='ignore')\n",
    "\n",
    "required_columns = ['cpu_milli', 'memory_mib', 'gpu_milli']\n",
    "for col in required_columns:\n",
    "    if col not in pod_data.columns:\n",
    "        pod_data[col] = 0\n",
    "\n",
    "print(\"Final Columns:\", pod_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pod & Node Failure Prediction  -  pod_phase == Failed or Pending\n",
    "### Resource Exhaustion (CPU, Memory, Disk)\tcpu_utilization > 90%, memory_utilization > 90%\n",
    "### Network Failure Detection\tpacket_loss_rate > 3%, network_receive_mbps < 0.5\n",
    "### Service Disruptions (Logs)\tLogs: OOMKilled, CrashLoopBackOff, Evicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_data['cpu_utilization'] = pod_data['cpu_milli'] / 32000  # 32K max CPU\n",
    "pod_data['memory_utilization'] = pod_data['memory_mib'] / 262144  # 256GB max memory\n",
    "\n",
    "pod_data['gpu_utilization'] = np.where(pod_data['num_gpu'] > 0, pod_data['gpu_milli'] / 1000, 0)\n",
    "\n",
    "pod_data['runtime'] = pod_data['deletion_time'] - pod_data['creation_time']  # Pod lifespan\n",
    "pod_data['scheduling_delay'] = pod_data['scheduled_time'] - pod_data['creation_time']  # Scheduling delay\n",
    "\n",
    "pod_data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "pod_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_features = ['cpu_utilization', 'memory_utilization', 'gpu_utilization', 'runtime', 'scheduling_delay']\n",
    "\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "pod_data['anomaly_score'] = iso_forest.fit_predict(pod_data[anomaly_features])\n",
    "\n",
    "pod_data['anomaly'] = (pod_data['anomaly_score'] == -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996338337605273\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2250\n",
      "           1       1.00      1.00      1.00      3212\n",
      "\n",
      "    accuracy                           1.00      5462\n",
      "   macro avg       1.00      1.00      1.00      5462\n",
      "weighted avg       1.00      1.00      1.00      5462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['cpu_utilization', 'memory_utilization', 'gpu_utilization', 'runtime', 'scheduling_delay', 'anomaly']\n",
    "\n",
    "X = pod_data[features]\n",
    "y = pod_data['failure_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing if the dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure_label\n",
      "1    15855\n",
      "0    11452\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pod_data['failure_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on New Data: [1 0 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "new_predictions = model.predict(X_test[:10])\n",
    "print(\"Predictions on New Data:\", new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9018674478213109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Data Accuracy: 0.9992676675210546\n",
      "Future Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       910\n",
      "           1       1.00      1.00      1.00      1821\n",
      "\n",
      "    accuracy                           1.00      2731\n",
      "   macro avg       1.00      1.00      1.00      2731\n",
      "weighted avg       1.00      1.00      1.00      2731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'anomaly' not in future_data.columns:\n",
    "    future_data['anomaly'] = 0 \n",
    "\n",
    "features = ['cpu_utilization', 'memory_utilization', 'gpu_utilization', 'runtime', 'scheduling_delay', 'anomaly']\n",
    "X_future = future_data[features]\n",
    "\n",
    "X_future = scaler.transform(X_future)\n",
    "\n",
    "future_preds = model.predict(X_future)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Future Data Accuracy:\", accuracy_score(y_future, future_preds))\n",
    "print(\"Future Data Classification Report:\\n\", classification_report(y_future, future_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_data['event_OOMKilled'] = np.random.choice([0, 1], size=len(pod_data), p=[0.95, 0.05])\n",
    "pod_data['event_CrashLoopBackOff'] = np.random.choice([0, 1], size=len(pod_data), p=[0.90, 0.10]) \n",
    "pod_data['event_Evicted'] = np.random.choice([0, 1], size=len(pod_data), p=[0.97, 0.03])\n",
    "\n",
    "pod_data['service_failure'] = (\n",
    "    pod_data['event_OOMKilled'] | \n",
    "    pod_data['event_CrashLoopBackOff'] | \n",
    "    pod_data['event_Evicted']\n",
    ").astype(int)\n",
    "\n",
    "pod_data['failure_label'] = (\n",
    "    pod_data['failure_label'] | pod_data['service_failure']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: Index(['name', 'cpu_milli', 'memory_mib', 'num_gpu', 'gpu_milli', 'gpu_spec',\n",
      "       'qos', 'pod_phase', 'creation_time', 'deletion_time', 'scheduled_time',\n",
      "       'sn', 'gpu', 'model', 'cpu_utilization', 'memory_utilization',\n",
      "       'gpu_utilization', 'runtime', 'scheduling_delay', 'failure_label',\n",
      "       'event_OOMKilled', 'event_CrashLoopBackOff', 'event_Evicted',\n",
      "       'service_failure'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns:\", pod_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if 'anomaly' not in pod_data.columns:\n",
    "    pod_data['anomaly'] = 0\n",
    "\n",
    "for col in ['network_receive_mbps', 'network_transmit_mbps', 'packet_loss_rate']:\n",
    "    if col not in pod_data.columns:\n",
    "        pod_data[col] = np.random.uniform(0.1, 100, size=len(pod_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Model Accuracy: 0.9921274258513365\n",
      "Updated Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1850\n",
      "           1       0.99      1.00      0.99      3612\n",
      "\n",
      "    accuracy                           0.99      5462\n",
      "   macro avg       0.99      0.99      0.99      5462\n",
      "weighted avg       0.99      0.99      0.99      5462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'cpu_utilization', 'memory_utilization', 'gpu_utilization', 'runtime', 'scheduling_delay', 'anomaly',\n",
    "    'network_receive_mbps', 'network_transmit_mbps', 'packet_loss_rate',\n",
    "    'event_OOMKilled', 'event_CrashLoopBackOff', 'event_Evicted'\n",
    "]\n",
    "\n",
    "X = pod_data[features]\n",
    "y = pod_data['failure_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Updated Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Updated Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 'Running' 'Pending' 'Succeeded' 'Failed']\n"
     ]
    }
   ],
   "source": [
    "print(pod_data['pod_phase'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure_type\n",
      "3    17785\n",
      "1     6672\n",
      "2     2329\n",
      "4      500\n",
      "0      430\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "majority = pod_data[pod_data['failure_type'] != 4]\n",
    "minority = pod_data[pod_data['failure_type'] == 4]\n",
    "\n",
    "minority_upsampled = resample(minority, replace=True, n_samples=500, random_state=42)\n",
    "\n",
    "pod_data_balanced = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "print(pod_data_balanced['failure_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Class Model Accuracy: 0.9895642621750275\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        86\n",
      "           1       0.98      0.98      0.98      1335\n",
      "           2       0.99      0.99      0.99       466\n",
      "           3       0.99      0.99      0.99      3557\n",
      "           4       1.00      0.83      0.91        18\n",
      "\n",
      "    accuracy                           0.99      5462\n",
      "   macro avg       0.98      0.95      0.97      5462\n",
      "weighted avg       0.99      0.99      0.99      5462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "features = [\n",
    "    'cpu_utilization', 'memory_utilization', 'gpu_utilization', 'runtime', \n",
    "    'scheduling_delay', 'network_receive_mbps', 'packet_loss_rate', \n",
    "    'event_OOMKilled', 'event_CrashLoopBackOff', 'event_Evicted'\n",
    "]\n",
    "\n",
    "X = pod_data[features]\n",
    "y = pod_data['failure_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Multi-Class Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
